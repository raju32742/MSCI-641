{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd8b1fc-9a7d-4019-99eb-feffe5cdbfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNB with unigrams w stopwords...\n",
      "Best alpha: 1\n",
      "Best Validation Accuracy: 0.8074375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "def load_data(data_dir, filename):\n",
    "    with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:\n",
    "        data = [line.strip() for line in f]\n",
    "    return data\n",
    "\n",
    "def train_and_evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, vectorizer, filename):\n",
    "    alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    \n",
    "    best_alpha = None\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # Iterate over alpha values\n",
    "    for alpha in alphas:\n",
    "        # Train a MultinomialNB model with the current alpha\n",
    "        model = MultinomialNB(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the validation set\n",
    "        val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate accuracy of the predictions\n",
    "        accuracy = accuracy_score(y_val, val_pred)        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_alpha = alpha\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "    \n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy}\")\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Save the best model and vectorizer's information to a file\n",
    "    model_data = {\n",
    "        'model': best_model,\n",
    "        'vocabulary': vectorizer.vocabulary_,\n",
    "        'ngram_range': vectorizer.ngram_range,\n",
    "        'token_pattern': vectorizer.token_pattern\n",
    "    }\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model_data, file)\n",
    "    \n",
    "    return best_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "def print_results_in_table(test_acc_uni, test_acc_bi, test_acc_uni_bi, test_acc_uni_ns, test_acc_bi_ns, test_acc_uni_bi_ns):\n",
    "    # Create a table with the results\n",
    "    table = [\n",
    "        [\"Stopwords removed\", \"Text features\", \"Accuracy (test set)\"],\n",
    "        [\"yes\", \"unigrams\", test_acc_uni_ns],\n",
    "        [\"yes\", \"bigrams\", test_acc_bi_ns],\n",
    "        [\"yes\", \"unigrams+bigrams\", test_acc_uni_bi_ns],\n",
    "        [\"no\", \"unigrams\", test_acc_uni],\n",
    "        [\"no\", \"bigrams\", test_acc_bi],\n",
    "        [\"no\", \"unigrams+bigrams\", test_acc_uni_bi],\n",
    "    ]\n",
    "    # Print the table\n",
    "    print(\"\\nClassification accuracy on the test sets:\")\n",
    "    for row in table:\n",
    "        print(\"{:<20} {:<20} {:<20}\".format(*row))\n",
    "\n",
    "\n",
    "    \n",
    "data_dir = \"/Users/raju/Raju Mac/UW/UW/Spring 24/MSCI 641/Assignment/a1/data\"\n",
    "out_dir = \"/Users/raju/Raju Mac/UW/UW/Spring 24/MSCI 641/Assignment/a2/data\"\n",
    "#Data with stop Words\n",
    "train_data = load_data(data_dir, 'train.csv')\n",
    "val_data = load_data(data_dir, 'val.csv')\n",
    "test_data = load_data(data_dir, 'test.csv')\n",
    "\n",
    "#Data without stop words\n",
    "train_data_ns = load_data(data_dir, 'train_ns.csv')\n",
    "val_data_ns = load_data(data_dir, 'val_ns.csv')\n",
    "test_data_ns = load_data(data_dir, 'test_ns.csv')\n",
    "\n",
    "#labels data\n",
    "train_labels = load_data(data_dir, 'train_labels.csv')\n",
    "val_labels = load_data(data_dir, 'val_labels.csv')\n",
    "test_labels = load_data(data_dir, 'test_labels.csv')\n",
    "\n",
    "#Define Unigram, bigram and uni-bigram models for vectorization\n",
    "uni_vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "uni_bi_vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "#Vectorize the data with stop words\n",
    "train_uni = uni_vectorizer.fit_transform(train_data)\n",
    "val_uni = uni_vectorizer.transform(val_data)\n",
    "test_uni = uni_vectorizer.transform(test_data)\n",
    "\n",
    "train_bi = bi_vectorizer.fit_transform(train_data)\n",
    "val_bi = bi_vectorizer.transform(val_data)\n",
    "test_bi = bi_vectorizer.transform(test_data)\n",
    "\n",
    "train_uni_bi = uni_bi_vectorizer.fit_transform(train_data)\n",
    "val_uni_bi = uni_bi_vectorizer.transform(val_data)\n",
    "test_uni_bi = uni_bi_vectorizer.transform(test_data)\n",
    "\n",
    "\n",
    "# Vectorize the data without stop words\n",
    "train_ns_uni = uni_vectorizer.fit_transform(train_data_ns)\n",
    "val_ns_uni = uni_vectorizer.transform(val_data_ns)\n",
    "test_ns_uni = uni_vectorizer.transform(test_data_ns)\n",
    "\n",
    "train_ns_bi = bi_vectorizer.fit_transform(train_data_ns)\n",
    "val_ns_bi = bi_vectorizer.transform(val_data_ns)\n",
    "test_ns_bi = bi_vectorizer.transform(test_data_ns)\n",
    "\n",
    "train_ns_uni_bi = uni_bi_vectorizer.fit_transform(train_data_ns)\n",
    "val_ns_uni_bi = uni_bi_vectorizer.transform(val_data_ns)\n",
    "test_ns_uni_bi = uni_bi_vectorizer.transform(test_data_ns)\n",
    "\n",
    "print(\"Training MNB with unigrams w stopwords...\")\n",
    "val_acc_uni, test_acc_uni = train_and_evaluate_model(train_uni, train_labels, val_uni, val_labels, test_uni, test_labels, uni_vectorizer, os.path.join(out_dir, 'mnb_uni.pkl'))\n",
    "# print(\"Training MNB with bigrams w stopwords...\")\n",
    "# val_acc_bi, test_acc_bi = train_and_evaluate_model(train_bi, train_labels, val_bi, val_labels, test_bi, test_labels, bi_vectorizer, os.path.join(out_dir, 'mnb_bi.pkl'))\n",
    "# print(\"Training MNB with unigrams and bigrams w stopwords...\")\n",
    "# val_acc_uni_bi, test_acc_uni_bi = train_and_evaluate_model(train_uni_bi, train_labels, val_uni_bi, val_labels, test_uni_bi, test_labels, uni_bi_vectorizer, os.path.join(out_dir, 'mnb_uni_bi.pkl'))\n",
    "\n",
    "# print(\"Training MNB with unigrams w/o stopwords...\")\n",
    "# val_acc_uni_ns, test_acc_uni_ns = train_and_evaluate_model(train_ns_uni, train_labels, val_ns_uni, val_labels, test_ns_uni, test_labels, uni_vectorizer, os.path.join(out_dir, 'mnb_uni_ns.pkl'))\n",
    "# print(\"Training MNB with bigrams w/o stopwords...\")\n",
    "# val_acc_bi_ns, test_acc_bi_ns = train_and_evaluate_model(train_ns_bi, train_labels, val_ns_bi, val_labels, test_ns_bi, test_labels, bi_vectorizer, os.path.join(out_dir, 'mnb_bi_ns.pkl'))\n",
    "# print(\"Training MNB with unigrams and bigrams w/o stopwords...\")\n",
    "# val_acc_uni_bi_ns, test_acc_uni_bi_ns = train_and_evaluate_model(train_ns_uni_bi, train_labels, val_ns_uni_bi, val_labels, test_ns_uni_bi, test_labels, uni_bi_vectorizer, os.path.join(out_dir, 'mnb_uni_bi_ns.pkl'))\n",
    "\n",
    "# # Print the accuracy results\n",
    "# print(\"\\nClassification accuracy on the test sets:\")\n",
    "# print(f\"Unigrams w stopwords - Test: {test_acc_uni}\")\n",
    "# print(f\"Bigrams w stopwords - Test: {test_acc_bi}\")\n",
    "# print(f\"Unigrams+bigrams w stopwords - Test: {test_acc_uni_bi}\")\n",
    "# print(f\"Unigrams w/o stopwords - Test: {test_acc_uni_ns}\")\n",
    "# print(f\"Bigrams w/o stopwords - Test: {test_acc_bi_ns}\")\n",
    "# print(f\"Unigrams+bigrams w/o stopwords - Test: {test_acc_uni_bi_ns}\")\n",
    "# print_results_in_table(test_acc_uni, test_acc_bi, test_acc_uni_bi, test_acc_uni_ns, test_acc_bi_ns, test_acc_uni_bi_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40dc98-eb55-43f3-8f5d-5a65cb261db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204b8a2-7729-4dc8-b541-28abbcda4fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
